{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RizkyWidodo-project/EJ-EONC_Project/blob/main/R5py_Centroid_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setting up the Environment (Installing R5py and Dependencies)\n"
      ],
      "metadata": {
        "id": "lCnSSLKT0-kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java Development Kit (JDK) - Version 21\n",
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install -y openjdk-21-jdk-headless -qq > /dev/null\n",
        "print(\"OpenJDK 21 installed.\")\n",
        "\n",
        "# Set JAVA_HOME environment variable to Java 21\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-21-openjdk-amd64\"\n",
        "print(f\"JAVA_HOME set to: {os.environ['JAVA_HOME']}\")\n",
        "\n",
        "# Verify Java version\n",
        "!java -version\n",
        "\n",
        "# Install r5py and other necessary libraries\n",
        "!pip install pandas geopandas r5py\n",
        "print(\"r5py, pandas, and geopandas installed.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "OpenJDK 21 installed.\n",
            "JAVA_HOME set to: /usr/lib/jvm/java-21-openjdk-amd64\n",
            "openjdk version \"21.0.7\" 2025-04-15\n",
            "OpenJDK Runtime Environment (build 21.0.7+6-Ubuntu-0ubuntu122.04)\n",
            "OpenJDK 64-Bit Server VM (build 21.0.7+6-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Collecting r5py\n",
            "  Downloading r5py-1.0.5-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas) (24.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (3.7.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas) (2.1.1)\n",
            "Collecting ConfigArgParse (from r5py)\n",
            "  Downloading configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from r5py) (3.18.0)\n",
            "Collecting geohexgrid (from r5py)\n",
            "  Downloading geohexgrid-2.1.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from r5py) (1.5.0)\n",
            "Collecting jpype1 (from r5py)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from r5py) (5.9.5)\n",
            "Collecting rasterio (from r5py)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from r5py) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from r5py) (1.6.1)\n",
            "Collecting simplification (from r5py)\n",
            "  Downloading simplification-0.7.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from r5py) (4.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pyogrio>=0.7.2->geopandas) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting rtree>=1.0.0 (from geohexgrid->r5py)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting affine (from rasterio->r5py)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->r5py) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->r5py) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio->r5py)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio->r5py)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from rasterio->r5py) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->r5py) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->r5py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->r5py) (2.4.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->r5py) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->r5py) (3.6.0)\n",
            "Downloading r5py-1.0.5-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Downloading geohexgrid-2.1.1-py3-none-any.whl (6.8 kB)\n",
            "Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simplification-0.7.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m747.0/747.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: simplification, rtree, jpype1, ConfigArgParse, cligj, click-plugins, affine, rasterio, geohexgrid, r5py\n",
            "Successfully installed ConfigArgParse-1.7.1 affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 geohexgrid-2.1.1 jpype1-1.5.2 r5py-1.0.5 rasterio-1.4.3 rtree-1.4.0 simplification-0.7.13\n",
            "r5py, pandas, and geopandas installed.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqimOyD50-kH",
        "outputId": "4fd7a9df-6a4d-4e65-f490-280e148d0f8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "#2. Writing the R5py Code for Assignment\n",
        "\n",
        "## 2.1. Import Libraries and Load Data"
      ],
      "metadata": {
        "id": "kkkGnX-90-kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from r5py import TransportNetwork, TravelTimeMatrixComputer, TransportMode\n",
        "from datetime import datetime\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Define base path to your Google Drive folder ---\n",
        "gdrive_base_path = \"file_path\"\n",
        "\n",
        "# --- Define file names and full paths ---\n",
        "centroids_gpkg_file = os.path.join(gdrive_base_path, \"centroids.gpkg\")\n",
        "facilities_csv_file = os.path.join(gdrive_base_path, \"EONC Facility.csv\")\n",
        "osm_file = os.path.join(gdrive_base_path, \"east java.osm.pbf\")\n",
        "output_csv_file = os.path.join(gdrive_base_path, \"output.csv\")\n",
        "\n",
        "# --- Define actual column names ---\n",
        "centroid_id_col = 'cell_id'\n",
        "centroid_lat_col = 'centroids_lat'\n",
        "centroid_lon_col = 'centroids_lng'\n",
        "\n",
        "facility_id_col = 'facility_id'\n",
        "facility_lat_col = 'Latitude'\n",
        "facility_lon_col = 'Longitude'\n",
        "\n",
        "# Load centroids\n",
        "centroids_df = pd.read_csv(centroids_csv_file)\n",
        "print(f\"--- First 5 rows of Centroids CSV ({centroids_csv_file}): ---\")\n",
        "print(centroids_df.head())\n",
        "print(\"\\n--- Info for Centroids CSV: ---\")\n",
        "centroids_df.info()\n",
        "\n",
        "# Convert centroids_df to GeoDataFrame\n",
        "# Ensure the ID column is suitable for R5py (string or int, unique)\n",
        "centroids_df[centroid_id_col] = centroids_df[centroid_id_col].astype(str)\n",
        "centroids_gdf = gpd.GeoDataFrame(\n",
        "    centroids_df,\n",
        "    geometry=gpd.points_from_xy(centroids_df[centroid_lon_col], centroids_df[centroid_lat_col]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "# Rename the ID column to 'id' for r5py compatibility\n",
        "if centroid_id_col != 'id':\n",
        "    centroids_gdf = centroids_gdf.rename(columns={centroid_id_col: 'id'})\n",
        "else:\n",
        "    centroids_gdf['id'] = centroids_gdf['id'].astype(str) # Ensure 'id' column exists and is string\n",
        "\n",
        "print(f\"\\nLoaded and processed {len(centroids_gdf)} centroids.\")\n",
        "print(centroids_gdf[['id', 'geometry']].head())\n",
        "\n",
        "\n",
        "# Load healthcare facilities\n",
        "print(f\"\\nLoading facilities from: {facilities_csv_file}\")\n",
        "facilities_df = pd.read_csv(facilities_csv_file)\n",
        "print(f\"\\n--- First 5 rows of Facilities CSV: ---\")\n",
        "print(facilities_df.head())\n",
        "print(\"\\n--- Info for Facilities CSV: ---\")\n",
        "facilities_df.info()\n",
        "\n",
        "# Convert facilities_df to GeoDataFrame using 'temp_unique_facility_id'\n",
        "# The facility_id_col variable (defined in Step 4) should now be 'temp_unique_facility_id'\n",
        "facilities_df[facility_id_col] = facilities_df[facility_id_col].astype(str) # Ensure it's string\n",
        "facilities_gdf = gpd.GeoDataFrame(\n",
        "    facilities_df,\n",
        "    geometry=gpd.points_from_xy(facilities_df[facility_lon_col], facilities_df[facility_lat_col]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "# Rename the ID column to 'id' for r5py compatibility\n",
        "if facility_id_col != 'id': # facility_id_col is 'temp_unique_facility_id'\n",
        "    facilities_gdf = facilities_gdf.rename(columns={facility_id_col: 'id'})\n",
        "else:\n",
        "    facilities_gdf['id'] = facilities_gdf['id'].astype(str)\n",
        "\n",
        "print(f\"\\nLoaded and processed {len(facilities_gdf)} healthcare facilities.\")\n",
        "print(facilities_gdf[['id', 'geometry']].head()) # Check the new 'id' column\n",
        "\n",
        "print(f\"\\nUsing OSM file: {osm_file}. Make sure this is the correct name of your uploaded .pbf file.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "8SZ83Qk60-kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Checking for duplicate IDs in centroids_gdf ---\")\n",
        "duplicate_centroid_ids = centroids_gdf['id'].value_counts()[centroids_gdf['id'].value_counts() > 1]\n",
        "if not duplicate_centroid_ids.empty:\n",
        "    print(\"Found duplicate IDs in centroids_gdf:\")\n",
        "    print(duplicate_centroid_ids)\n",
        "    print(\"\\nExample rows with one of the duplicate IDs (first duplicate found):\")\n",
        "    if len(duplicate_centroid_ids.index) > 0:\n",
        "      print(centroids_gdf[centroids_gdf['id'] == duplicate_centroid_ids.index[0]])\n",
        "else:\n",
        "    print(\"No duplicate IDs found in centroids_gdf. 'id' column is unique.\")\n",
        "\n",
        "print(\"\\n--- Checking for duplicate IDs in facilities_gdf ---\")\n",
        "duplicate_facility_ids = facilities_gdf['id'].value_counts()[facilities_gdf['id'].value_counts() > 1]\n",
        "if not duplicate_facility_ids.empty:\n",
        "    print(\"Found duplicate IDs in facilities_gdf:\")\n",
        "    print(duplicate_facility_ids)\n",
        "    print(\"\\nExample rows with one of the duplicate IDs (first duplicate found):\")\n",
        "    if len(duplicate_facility_ids.index) > 0:\n",
        "        print(facilities_gdf[facilities_gdf['id'] == duplicate_facility_ids.index[0]])\n",
        "else:\n",
        "    print(\"No duplicate IDs found in facilities_gdf. 'id' column is unique.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RquFjbBNA6q0",
        "outputId": "20d69d4c-5ec2-4fea-f8e2-64eb89846602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Checking for duplicate IDs in centroids_gdf ---\n",
            "No duplicate IDs found in centroids_gdf. 'id' column is unique.\n",
            "\n",
            "--- Checking for duplicate IDs in facilities_gdf ---\n",
            "No duplicate IDs found in facilities_gdf. 'id' column is unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Initialize the Transport Network"
      ],
      "metadata": {
        "id": "F7haosgX0-kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the transport network from the OSM file\n",
        "print(f\"\\nBuilding transport network from {osm_file}...\")\n",
        "transport_network = TransportNetwork(osm_pbf=osm_file)\n",
        "print(\"Transport network built successfully!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building transport network from /content/drive/My Drive/MAP5010 Research Project/Assign Centroid/east java.osm.pbf...\n",
            "Transport network built successfully!\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2nmXRxb0-kK",
        "outputId": "7b48d478-aed4-409c-cbe7-52ad0a858219"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Compute Travel Times (for R5py to Determine \"Nearest\")"
      ],
      "metadata": {
        "id": "0qYdFhoq0-kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In Step 5.3 - TEMPORARY DIAGNOSTIC TEST\n",
        "\n",
        "from r5py import TravelTimeMatrix\n",
        "from datetime import datetime\n",
        "import pandas as pd # Just in case it's needed for other parts you might add\n",
        "\n",
        "departure_datetime = datetime(2025, 5, 27, 10, 0, 0)\n",
        "\n",
        "print(\"--- DIAGNOSTIC TEST: Initializing TravelTimeMatrix with only 10 origins ---\")\n",
        "try:\n",
        "    # Using only the first 10 centroids for this test\n",
        "    test_origins = centroids_gdf[['id', 'geometry']].head(10)\n",
        "    all_transport_modes = [\n",
        "        TransportMode.WALK,\n",
        "        TransportMode.BICYCLE,\n",
        "        TransportMode.TRANSIT,\n",
        "        TransportMode.CAR\n",
        "]\n",
        "    travel_time_matrix_test = TravelTimeMatrix(\n",
        "        transport_network,\n",
        "        origins=test_origins, # Using the small subset of origins\n",
        "        destinations=facilities_gdf[['id', 'geometry']], # Still using all destinations for this test\n",
        "        departure=departure_datetime,\n",
        "        transport_modes=all_transport_modes\n",
        "    )\n",
        "    print(\"SUCCESS: TravelTimeMatrix initialized QUICKLY with 10 origins.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR during diagnostic test: {e}\")\n",
        "\n",
        "print(\"--- End of DIAGNOSTIC TEST ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpfL7oTt2wL0",
        "outputId": "45ad43a4-d1bf-49e4-e608-499073633f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DIAGNOSTIC TEST: Initializing TravelTimeMatrix with only 10 origins ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/r5py/r5/regional_task.py:196: RuntimeWarning: The currently loaded GTFS data sets do not define any services on 2025-05-27.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: TravelTimeMatrix initialized QUICKLY with 10 origins.\n",
            "--- End of DIAGNOSTIC TEST ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define departure time (R5py requires a specific datetime)\n",
        "departure_datetime = datetime(2025, 5, 27, 10, 0, 0) # Year, Month, Day, Hour, Minute, Second\n",
        "\n",
        "# Initialize the TravelTimeMatrixComputer\n",
        "# It's crucial that centroids_gdf and facilities_gdf have an 'id' column and a 'geometry' column\n",
        "all_transport_modes = [\n",
        "        TransportMode.WALK,\n",
        "        TransportMode.BICYCLE,\n",
        "        TransportMode.TRANSIT,\n",
        "        TransportMode.CAR\n",
        "]\n",
        "travel_time_computer = TravelTimeMatrixComputer(\n",
        "    transport_network,\n",
        "    origins=centroids_gdf[['id', 'geometry']],      # Uses the processed GeoDataFrames\n",
        "    destinations=facilities_gdf[['id', 'geometry']],# Uses the processed GeoDataFrames\n",
        "    departure=departure_datetime,\n",
        "    transport_modes=all_transport_modes # Driving mode\n",
        ")\n",
        "print(\"\\nTravelTimeMatrixComputer initialized.\")\n",
        "\n",
        "# Compute the travel times (R5py uses these to determine 'nearest')\n",
        "print(\"Computing travel time matrix for assignment... (this may take a while)\")\n",
        "r5py_travel_times_df = travel_time_computer.compute_travel_times()\n",
        "\n",
        "if r5py_travel_times_df.empty:\n",
        "    print(\"WARNING: The computed travel time matrix is empty!\")\n",
        "    print(\"Please check:\")\n",
        "    print(\"1. OSM file coverage: Does your OSM map cover the area of your centroids and facilities?\")\n",
        "    print(\"2. Coordinate systems: Are centroids and facilities correctly located (check latitudes/longitudes)?\")\n",
        "    print(\"3. R5py errors during network build or computation.\")\n",
        "else:\n",
        "    print(\"R5py travel time matrix computed!\")\n",
        "    print(r5py_travel_times_df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-4cdaeacb74dc>:12: DeprecationWarning: Use `TravelTimeMatrix` instead, `TravelTimeMatrixComputer will be deprecated in a future release.\n",
            "  travel_time_computer = TravelTimeMatrixComputer(\n",
            "/usr/local/lib/python3.11/dist-packages/r5py/r5/regional_task.py:196: RuntimeWarning: The currently loaded GTFS data sets do not define any services on 2025-05-27.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TravelTimeMatrixComputer initialized.\n",
            "Computing travel time matrix for assignment... (this may take a while)\n",
            "R5py travel time matrix computed!\n",
            "  from_id to_id  travel_time\n",
            "0  150558     0          NaN\n",
            "1  150558     1          NaN\n",
            "2  150558     2          NaN\n",
            "3  150558     3          NaN\n",
            "4  150558     4          NaN\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJovzDE70-kK",
        "outputId": "0b04559a-3070-4d45-cb13-ac82dbdfce8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Assign Centroids to the Nearest Facility (based on R5py's calculation)"
      ],
      "metadata": {
        "id": "UzhahHaF0-kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign each centroid to the nearest facility based on R5py's network travel times\n",
        "assigned_centroids_df = pd.DataFrame() # Initialize an empty DataFrame for results\n",
        "\n",
        "if not r5py_travel_times_df.empty:\n",
        "    # Filter out rows where travel_time is NaN before sorting and grouping\n",
        "    r5py_travel_times_df_cleaned = r5py_travel_times_df.dropna(subset=['travel_time'])\n",
        "\n",
        "    if not r5py_travel_times_df_cleaned.empty:\n",
        "        r5py_travel_times_df_sorted = r5py_travel_times_df_cleaned.sort_values(by=['from_id', 'travel_time'])\n",
        "        nearest_facility_assignment_r5py = r5py_travel_times_df_sorted.loc[\n",
        "            r5py_travel_times_df_sorted.groupby('from_id')['travel_time'].idxmin()\n",
        "        ]\n",
        "\n",
        "        nearest_facility_assignment_r5py = nearest_facility_assignment_r5py.rename(\n",
        "            columns={\n",
        "                'from_id': 'centroid_id_r5py', # Renaming to avoid clash if 'centroid_id' is an original col name\n",
        "                'to_id': 'nearest_facility_id',\n",
        "                'travel_time': 'r5py_travel_time_for_assignment (min)'\n",
        "            }\n",
        "        )\n",
        "\n",
        "        print(\"\\nAssignment of centroids to nearest facility (based on R5py):\")\n",
        "        print(nearest_facility_assignment_r5py.head())\n",
        "\n",
        "        # --- Merge with original centroid data ---\n",
        "        centroids_df_for_merge = centroids_df.copy()\n",
        "        centroids_df_for_merge[centroid_id_col] = centroids_df_for_merge[centroid_id_col].astype(str)\n",
        "\n",
        "\n",
        "        assigned_centroids_df = centroids_df_for_merge.merge(\n",
        "            nearest_facility_assignment_r5py,\n",
        "            left_on=centroid_id_col, # Original ID column from centroids_df e.g. 'cell_id'\n",
        "            right_on='centroid_id_r5py', # This 'id' came from the centroids_gdf that used centroid_id_col\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Clean up columns: drop the temporary 'centroid_id_r5py' if it's different from the original centroid id column name\n",
        "        if 'centroid_id_r5py' in assigned_centroids_df.columns and 'centroid_id_r5py' != centroid_id_col:\n",
        "            assigned_centroids_df = assigned_centroids_df.drop(columns=['centroid_id_r5py'])\n",
        "\n",
        "        print(\"\\nFinal assignment data merged with original centroid details:\")\n",
        "\n",
        "        # Define the columns you expect in the final output\n",
        "        # (original centroid columns + new assignment columns)\n",
        "        expected_display_cols = [centroid_id_col, centroid_lat_col, centroid_lon_col,\n",
        "                                 'nearest_facility_id', 'r5py_travel_time_for_assignment (min)']\n",
        "\n",
        "        # Filter for columns that actually exist in the DataFrame to avoid KeyError\n",
        "        actual_display_cols = [col for col in expected_display_cols if col in assigned_centroids_df.columns]\n",
        "\n",
        "        if not assigned_centroids_df.empty:\n",
        "            # Display only relevant columns and handle potential missing columns gracefully\n",
        "            display_cols = [col for col in actual_display_cols if col in assigned_centroids_df.columns]\n",
        "            if display_cols:\n",
        "                 print(assigned_centroids_df[display_cols].head())\n",
        "            else:\n",
        "                 print(\"Could not find expected display columns in the merged DataFrame.\")\n",
        "                 print(\"Columns available:\", assigned_centroids_df.columns.tolist())\n",
        "        else:\n",
        "            print(\"assigned_centroids_df is empty after merge. Check merge keys and logic.\")\n",
        "    else:\n",
        "        print(\"After removing NaNs, the travel time matrix is empty. No valid routes found for any origin-destination pair.\")\n",
        "\n",
        "else:\n",
        "    print(\"Travel time matrix was empty. Cannot perform assignment. Please check previous steps.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assignment of centroids to nearest facility (based on R5py):\n",
            "      centroid_id_r5py nearest_facility_id  \\\n",
            "44610           100110                 280   \n",
            "6061            102603                 264   \n",
            "6402            103018                 264   \n",
            "12025           104279                  90   \n",
            "12366           104694                  90   \n",
            "\n",
            "       r5py_travel_time_for_assignment (min)  \n",
            "44610                                   62.0  \n",
            "6061                                    44.0  \n",
            "6402                                    44.0  \n",
            "12025                                   31.0  \n",
            "12366                                   45.0  \n",
            "\n",
            "Final assignment data merged with original centroid details:\n",
            "  cell_id  centroids_lat  centroids_lng nearest_facility_id  \\\n",
            "0  150558      -8.480965     113.714199                  25   \n",
            "1  150974      -8.476465     113.721993                  25   \n",
            "2  151805      -8.467465     113.737582                  25   \n",
            "3  152218      -8.444965     113.745376                  25   \n",
            "4  152634      -8.440465     113.753170                  25   \n",
            "\n",
            "   r5py_travel_time_for_assignment (min)  \n",
            "0                                   55.0  \n",
            "1                                   54.0  \n",
            "2                                   49.0  \n",
            "3                                   45.0  \n",
            "4                                   55.0  \n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "OZojGjOR0-kL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429e71f0-d011-4f92-d710-fe74b8bfdbba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Saving Your Assignment Results"
      ],
      "metadata": {
        "id": "LfQvmTg-0-kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the assignment results to a CSV file\n",
        "output_filename = \"ASSIGNMENT_R5py_centroids_to_facilities.csv\"\n",
        "\n",
        "if not assigned_centroids_df.empty:\n",
        "    # Select relevant columns for the output CSV.\n",
        "    # You'll need the original centroid ID, its lat/lon, and the ID of the assigned facility.\n",
        "    # The r5py_travel_time is optional but can be good for reference.\n",
        "\n",
        "    columns_to_save = []\n",
        "    # Add original centroid columns by their defined names\n",
        "    if centroid_id_col in assigned_centroids_df.columns:\n",
        "        columns_to_save.append(centroid_id_col)\n",
        "    if centroid_lat_col in assigned_centroids_df.columns:\n",
        "         columns_to_save.append(centroid_lat_col) # Make sure this is the original lat column\n",
        "    if centroid_lon_col in assigned_centroids_df.columns:\n",
        "        columns_to_save.append(centroid_lon_col) # Make sure this is the original lon column\n",
        "\n",
        "    # Add assignment specific columns\n",
        "    if 'nearest_facility_id' in assigned_centroids_df.columns:\n",
        "        columns_to_save.append('nearest_facility_id')\n",
        "    if 'r5py_travel_time_for_assignment (min)' in assigned_centroids_df.columns:\n",
        "        columns_to_save.append('r5py_travel_time_for_assignment (min)')\n",
        "\n",
        "    # Ensure no duplicate columns if, for example, centroid_id_col was 'id'\n",
        "    columns_to_save = sorted(list(set(columns_to_save)))\n",
        "\n",
        "\n",
        "    if columns_to_save: # if list is not empty\n",
        "        output_df = assigned_centroids_df[columns_to_save]\n",
        "        output_df.to_csv(output_filename, index=False)\n",
        "        print(f\"\\nAssignment results saved to {output_filename}\")\n",
        "        print(f\"Columns saved: {output_df.columns.tolist()}\")\n",
        "        print(\"This file contains original centroid data merged with its 'nearest_facility_id' and R5py's assignment travel time.\")\n",
        "        print(\"You can now use these pairs (centroid and its assigned nearest_facility_id) with the Google Maps API.\")\n",
        "    else:\n",
        "        print(\"\\nCould not determine columns to save. Saving all columns from assigned_centroids_df.\")\n",
        "        assigned_centroids_df.to_csv(output_filename, index=False)\n",
        "        print(f\"\\nAssignment results (all columns) saved to {output_filename}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo assignment data to save as the result DataFrame was empty.\")\n",
        "\n",
        "# You can download this file from the Colab \"Files\" tab on the left (refresh if needed)."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assignment results saved to ASSIGNMENT_R5py_centroids_to_facilities.csv\n",
            "Columns saved: ['cell_id', 'centroids_lat', 'centroids_lng', 'nearest_facility_id', 'r5py_travel_time_for_assignment (min)']\n",
            "This file contains original centroid data merged with its 'nearest_facility_id' and R5py's assignment travel time.\n",
            "You can now use these pairs (centroid and its assigned nearest_facility_id) with the Google Maps API.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "erbYlnaX0-kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df450a1-851a-489f-c7c6-930d1f2a6c41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "FACILITIES_GDF_ID_COL = 'id'\n",
        "FACILITIES_GDF_NAME_COL = 'nama_fasilitas'\n",
        "FACILITIES_GDF_GEOMETRY_COL = 'geometry'\n",
        "\n",
        "output_facility_name_col = 'nearest_facility_name'\n",
        "output_facility_lat_col = 'nearest_facility_latitude'\n",
        "output_facility_lon_col = 'nearest_facility_longitude'\n",
        "\n",
        "if not assigned_centroids_df.empty:\n",
        "    if 'nearest_facility_id' in assigned_centroids_df.columns:\n",
        "        if FACILITIES_GDF_ID_COL in facilities_gdf.columns and \\\n",
        "           FACILITIES_GDF_NAME_COL in facilities_gdf.columns and \\\n",
        "           FACILITIES_GDF_GEOMETRY_COL in facilities_gdf.columns:\n",
        "\n",
        "            facility_details_to_merge = pd.DataFrame({\n",
        "                FACILITIES_GDF_ID_COL: facilities_gdf[FACILITIES_GDF_ID_COL],\n",
        "                FACILITIES_GDF_NAME_COL: facilities_gdf[FACILITIES_GDF_NAME_COL],\n",
        "                'facility_temp_lat': facilities_gdf[FACILITIES_GDF_GEOMETRY_COL].y,\n",
        "                'facility_temp_lon': facilities_gdf[FACILITIES_GDF_GEOMETRY_COL].x\n",
        "            })\n",
        "\n",
        "            assigned_centroids_df = pd.merge(\n",
        "                assigned_centroids_df,\n",
        "                facility_details_to_merge,\n",
        "                left_on='nearest_facility_id',\n",
        "                right_on=FACILITIES_GDF_ID_COL,\n",
        "                how='left'\n",
        "            )\n",
        "\n",
        "            rename_map = {}\n",
        "            if FACILITIES_GDF_NAME_COL in assigned_centroids_df.columns:\n",
        "                rename_map[FACILITIES_GDF_NAME_COL] = output_facility_name_col\n",
        "            if 'facility_temp_lat' in assigned_centroids_df.columns:\n",
        "                rename_map['facility_temp_lat'] = output_facility_lat_col\n",
        "            if 'facility_temp_lon' in assigned_centroids_df.columns:\n",
        "                rename_map['facility_temp_lon'] = output_facility_lon_col\n",
        "\n",
        "            if rename_map:\n",
        "                assigned_centroids_df.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "            if FACILITIES_GDF_ID_COL != 'nearest_facility_id' and FACILITIES_GDF_ID_COL in assigned_centroids_df.columns:\n",
        "                assigned_centroids_df.drop(columns=[FACILITIES_GDF_ID_COL], inplace=True)\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "    else:\n",
        "        pass\n",
        "else:\n",
        "    pass\n",
        "\n",
        "output_filename = \"ASSIGNMENT_R5py_centroids_to_facilities_with_coords.csv\"\n",
        "\n",
        "if not assigned_centroids_df.empty:\n",
        "    columns_to_save = []\n",
        "\n",
        "    if centroid_id_col in assigned_centroids_df.columns:\n",
        "        columns_to_save.append(centroid_id_col)\n",
        "    if centroid_lat_col in assigned_centroids_df.columns:\n",
        "         columns_to_save.append(centroid_lat_col)\n",
        "    if centroid_lon_col in assigned_centroids_df.columns:\n",
        "        columns_to_save.append(centroid_lon_col)\n",
        "\n",
        "    if 'nearest_facility_id' in assigned_centroids_df.columns:\n",
        "        columns_to_save.append('nearest_facility_id')\n",
        "\n",
        "    if output_facility_name_col in assigned_centroids_df.columns:\n",
        "        columns_to_save.append(output_facility_name_col)\n",
        "\n",
        "    if output_facility_lat_col in assigned_centroids_df.columns:\n",
        "        columns_to_save.append(output_facility_lat_col)\n",
        "\n",
        "    if output_facility_lon_col in assigned_centroids_df.columns:\n",
        "        columns_to_save.append(output_facility_lon_col)\n",
        "\n",
        "    if 'r5py_travel_time_for_assignment (min)' in assigned_centroids_df.columns:\n",
        "        columns_to_save.append('r5py_travel_time_for_assignment (min)')\n",
        "\n",
        "    if columns_to_save:\n",
        "        columns_to_save = sorted(list(set(columns_to_save)))\n",
        "        final_columns_to_save = [col for col in columns_to_save if col in assigned_centroids_df.columns]\n",
        "\n",
        "        if final_columns_to_save:\n",
        "            output_df = assigned_centroids_df[final_columns_to_save]\n",
        "            output_df.to_csv(output_filename, index=False)\n",
        "            print(f\"\\nAssignment results saved to {output_filename}\")\n",
        "            print(f\"Columns saved: {output_df.columns.tolist()}\")\n",
        "        else:\n",
        "            assigned_centroids_df.to_csv(output_filename, index=False)\n",
        "            print(f\"\\nAssignment results (all columns) saved to {output_filename}\")\n",
        "    else:\n",
        "        assigned_centroids_df.to_csv(output_filename, index=False)\n",
        "        print(f\"\\nAssignment results (all columns) saved to {output_filename}\")\n",
        "else:\n",
        "    print(\"\\nNo assignment data to save as the result DataFrame was empty.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v024SksY6M5n",
        "outputId": "9355fb37-4d3a-4e0e-c6e7-0b71f4beb665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Assignment results saved to ASSIGNMENT_R5py_centroids_to_facilities_with_coords.csv\n",
            "Columns saved: ['cell_id', 'centroids_lat', 'centroids_lng', 'nearest_facility_id', 'r5py_travel_time_for_assignment (min)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not assigned_centroids_df.empty:\n",
        "    facilities_df_prefixed = facilities_df.copy()\n",
        "    # Ensure the original ID column name is used to create the prefixed column name\n",
        "    facilities_df_prefixed.columns = [\"HF_\" + col for col in facilities_df_prefixed.columns]\n",
        "    prefixed_facility_join_key = \"HF_\" + facility_id_col # Use the correct variable name for facility ID\n",
        "\n",
        "    # Ensure the merge uses the correct original column name from facilities_df for the join key\n",
        "    # The 'nearest_facility_id' in assigned_centroids_df corresponds to the original facility_id_col values.\n",
        "    # We need to join assigned_centroids_df on 'nearest_facility_id' with facilities_df_prefixed on the prefixed original ID.\n",
        "    final_report_df = pd.merge(\n",
        "        assigned_centroids_df, facilities_df_prefixed,\n",
        "        left_on='nearest_facility_id', right_on=prefixed_facility_join_key, how='left'\n",
        "    )\n",
        "\n",
        "    output_filepath = os.path.join(gdrive_base_path, \"FINAL_ASSIGNMENT_REPORT.csv\") # Define a single output file path\n",
        "    final_report_df.to_csv(output_filepath, index=False)\n",
        "    print(f\"Final assignment report saved to {output_filepath}\")\n",
        "\n",
        "else:\n",
        "    print(\"Assigned_centroids_df is empty. Cannot create the final report.\")\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYmHR6Xz66CG",
        "outputId": "936d9937-1a88-417a-dfd4-ba28be33833e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final assignment report saved to /content/drive/My Drive/MAP5010 Research Project/Assign Centroid/FINAL_ASSIGNMENT_REPORT.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}